---
title: "Of course they're putting ads in AI"
author: Justine Moore + Bryan Kim
date: 2026-02-01
url: https://a16z.com/putting-ads-in-ai/
source: a16z
---

# Of course they're putting ads in AI

The internet is a miracle of universal access to opportunity, inquiry and connection. And ads pay for that miracle. As Marc Andreessen [has long argued](https://x.com/tbpn/status/1989766915808764155), "if you take a principle stand against ads, you're also taking a stand against broad access." Ads are why we have nice things.

So, the announcement that OpenAI plans to launch ads for free users is probably **the biggest piece of news-that-isn't-actually-news of 2026**. Because of course, if you've been paying attention, the signs that this would happen have been everywhere. Fidji Simo joined OpenAI as CEO of Applications (many people interpreted this to mean "implement ads, just like she did at Facebook and Instacart"). Sam Altman had been teasing the rollout of ads on business podcasts.

But the main reason ads aren't a surprise is because they're the best way to bring a service on the internet to the largest possible number of consumers.

## Why Most People Don't Pay for AI

Understanding this requires understanding what people use AI for. Last year, OpenAI [published data](https://cdn.openai.com/pdf/a253471f-8260-40c6-a2cc-aa93fe9f142e/economic-research-chatgpt-usage-paper.pdf) on exactly this.

In short, **most people use AI for personal productivity**: writing emails, searching for information, and tutoring or advice. Meanwhile, higher value pursuits like programming make up a very small percentage of overall queries.

Programmers are some of the most committed users of LLMs, with some calibrating their sleep schedules to optimize for [daily usage limits](https://x.com/typedfemale/status/1955040883499470853?s=20). For these users, a $20 or $200/month subscription doesn't feel exorbitant — the value (the equivalent of a swarm of highly productive SWE interns) is orders of magnitude greater.

But for users using LLMs for general queries, advice, or writing help, the onus of actually paying is too great. Why would they pay for an answer to "why is the sky blue" when previously a Google search would give a good-enough answer for free?

The absolute number of ChatGPT subscribers is still enormous: 5-10% of 800M WAUs = 40-80M people. And the price point for Pro at $200 is ten times what we thought the ceiling was for consumer software subscriptions. But if you want to get ChatGPT to a billion people (and beyond) for free, you need a product other than subscriptions.

## The good news: people actually like ads

Ask the average Instagram user, and they'll probably tell you that the ads they get are ridiculously useful — they get served products they actually want and need. Framing ads as exploitative is regressive: maybe we feel that way about TV ads, but targeted ads are actually pretty great content most of the time.

General rule of thumb: you need a minimum of **10M WAUs before introducing ads**. Many AI labs are already at this threshold.

## What Ad Units for LLMs Could Look Like

- **Higher value search and intent-based advertising:** OpenAI [has confirmed](https://openai.com/index/our-approach-to-advertising-and-expanding-access/) these kinds of advertisements (ingredients for recipes, hotel recommendations for trips) are coming to free and low cost-tier users. These ads will stand apart from answers and be clearly labeled as sponsored.

- **Context-based ads in the style of Instagram:** Ben Thompson has made the point that OpenAI should've introduced ads much earlier to ChatGPT responses. Given the amount of personal information and memory OpenAI has, there is plenty of opportunity to build a similar ad product for ChatGPT. Instagram and TikTok can deliver an amazing ad experience showing you products you never knew you wanted. Can you transpose a more "lean-back" ad experience on Instagram into the more engagement-heavy model of using ChatGPT? It's a much harder problem — and a more lucrative one to get right.

- **Affiliate commerce:** OpenAI announced an instant checkout function in collaboration with marketplace platforms. You can imagine this building into its own dedicated shopping vertical, where an agent proactively sources items and the model provider gets a cut of revenue.

- **Games:** App install ads (many of which were for mobile games) were a huge percentage of Facebook's ad growth for years. Games are so inherently profitable that it's not hard to imagine big ad budgets being spun up here.

- **Goal-based bidding:** What if you could set a bounty for a specific query (e.g., $10 for Noe Valley real estate alerts) and have a model throw an outsize amount of compute at a particular outcome? You'd get perfect price discrimination based on the determined "value" of a question.

- **Subscriptions for AI entertainment and companions:** CharacterAI has one of the highest WAU counts of any non-lab AI company. They can get away with charging $9.99/month because what they offer is a hybrid of companionship and entertainment.

## The Bottom Line

Monetization is still an unsolved problem in AI, with the majority of users enjoying the free tier of their preferred LLM. But this will only be temporary: **the history of the internet has taught us that ads find a way.**
