# Why now?

**Author:** @venturetwins  
**Date:** 2026-01-21T15:48:59.000Z  
**URL:** https://x.com/venturetwins/article/2014002290588615021  
**Images:** 3  

---

2025 was unquestionably the year of video. AI-generated ads went mainstream, launch videos from seed-stage startups got millions of views, and video podcasts and interviews exploded.

What you didn‚Äôt see was all the editing work behind the scenes. Cutting 90 minutes of footage into a three-minute short. Correcting lighting and audio in post-production. Searching for the right music and sound effects.

A common rule of thumb in video production is that you‚Äôll spend 80% of your time & energy on editing, and only 20% on filming (or now, generating). Crafting compelling video is a long and tedious process ‚Äì and few people have the ‚Äútaste‚Äù to do it right.

We now have the technology to hand over some of this work to AI agents. These agents will blow out the supply curve for quality video ‚Äì the kind of content that requires days (or weeks) from professional editors today. What Cursor did for coding, these agents will do for video production.

[![](https://pbs.twimg.com/amplify_video_thumb/2013802704703795200/img/tTXj7Mhq5mAE-33J.jpg)](blob:https://x.com/d63a0258-b298-4d5c-9b20-c213e3062ba3)

0:01 / 1:28

I couldn't write an article on video editing without making my own video üòâ

## Why now?

[![Image](https://pbs.twimg.com/media/G_Kpl0MaoAIMWYh?format=jpg&name=small)](/venturetwins/article/2014002290588615021/media/2013858450519007234)

There‚Äôs immense demand for agents that give anyone the skills (and taste) of a professional video editor. So why don‚Äôt these products already exist? There have been a few recent developments that have unlocked progress:

1. Vision models can process long video. You have to understand video before you can edit it. This is a non-trivial challenge. We‚Äôve seen a lot of progress with recent models like Gemini 3, GPT-5.2, Molmo 2, and Vidi2, which are inherently multimodal and have longer context windows. Gemini 3 can now process up to an hour of video! You can upload it as an input and ask the model to generate timestamped labels, find a specific moment, or just summarize what‚Äôs happening.
2. Models can now use tools. AI video editors need to be able to take action - not just describe what‚Äôs happening or suggest changes. We‚Äôre starting to see meaningful progress around LLMs as real agents that can use tools. One of my favorite examples of this is 

   [Claude using Blender](https://x.com/sidahuj/status/1899460492999184534)

    (a notoriously tricky product that many humans haven‚Äôt mastered). You can imagine how this evolves as you give agents access to more tools.
3. Image and video generation models have improved. I‚Äôm a big believer that many video production pipelines will be hybrid - a mix of AI and filmed content. Imagine filming interviews for a documentary, but generating B-roll or historical footage with AI. Or using a motion transfer model to take a reference animation and apply it to a real character. For any of these things to work, models needed to reach a level of quality & consistency to be valuable. Now, that‚Äôs finally happening.

## What will these agents do?

[![Image](https://pbs.twimg.com/media/G_KozhraoAIOhNI?format=jpg&name=small)](/venturetwins/article/2014002290588615021/media/2013857586555297794)

1. Process - whether you‚Äôre filming or generating, you‚Äôll likely end up with much more footage than you need (sometimes by a factor of hundreds). It‚Äôs time consuming to sort through all this video, organize it, and decide what to use. Products like 

   [Eddie AI](https://www.heyeddie.ai/)

    can take hours of footage and identify A- vs. B-roll, process multiple camera angles, and compare takes.
2. Orchestrate - if we assume many videos will include some element of AI in the future, we‚Äôll need agents that orchestrate all of the models. Imagine you want to add an AI animation to an educational video. You‚Äôll need an agent that can generate the images, send them to a video model, and stitch the outputs together. Products like 

   [Glif](https://glif.app/agents)

    are launching agents that coordinate between multiple models on a user‚Äôs behalf.
3. Polish - small details take a video from good to great. But if you‚Äôre not a pro, you may be overwhelmed by the flood of tasks needed to polish a video. For example - adjusting lighting between clips, cleaning noise out of the audio track, or taking out filler words (‚Äúummms‚Äù and ‚Äúuhhhs‚Äù) during an interview. Products like 

   [Descript](http://descript.com/)

   ‚Äôs Underlord agent can take a video, make all these changes for you, and deliver the final version.
4. Adapt - when you make a good video, you should adapt it for more reach. A common workflow is cutting a YouTube podcast into short clips with different aspect ratios to post on your X, Instagram, and TikTok accounts. Or even translate a video into other languages (and re-dub the speakers) to reach an international audience. Platforms like 

   [Overlap](http://overlap.ai/)

    allow you to set up node workflows for these adaptation tasks.
5. Optimize - the ultimate goal isn‚Äôt just replacing manual tasks with AI. It‚Äôs agents with taste that can make your videos better. There‚Äôs a reason people hire professional video editors! They spend years learning things like how to hook viewers, pacing a storyline, and using music to build an emotional reaction. YouTuber Emma Chamberlain famously said that she used to spend 30-40 hours editing a ~15 minute vlog.
   What if an AI agent could watch your footage, ask about your objectives, and then craft a few draft versions of a video for you to iterate on? You review and direct - ‚ÄúThe opening is too slow.‚Äù ‚ÄúCut the middle section.‚Äù ‚ÄúMake the ending hit harder‚Äù - and the agent executes.

## In conclusion...

I couldn't be more excited for the future of AI editing agents, as both a creator and consumer. They're going to dramatically increase the quality and quantity of video we see. When you give everyone the skills of a professional editor, you're going to get a LOT more stories that may not have otherwise been told.

I've been spending a ton of time testing all of the video agents that exist today - if you want to see demos of these products, check out 

[my full post](https://www.a16z.news/p/its-time-for-agentic-video-editing)

 on the 

[@a16z](https://x.com/@a16z)

 Substack.

And if you're building something here, please reach out (

[@venturetwins](https://x.com/@venturetwins)

 or jmoore@a16z.com). Bonus points if your agent can edit my video ‚¨ÜÔ∏è

Updating to add - Remotion 

[launched agent skills](https://x.com/Remotion/status/2013626968386765291)

right before this article was published, which is why it wasn't originally featured. But they're quite relevant so I'd be remiss not to add a note + link. These skills make it easy to create animations from text prompts. A few more examples of what you can do 

[here](https://x.com/Remotion/status/2014457057525571698)

.

---

## Images

![Image](https://pbs.twimg.com/media/G_MsOZSb0AAiaW4?format=jpg&name=900x900)

![Image](https://pbs.twimg.com/media/G_Kpl0MaoAIMWYh?format=jpg&name=small)

![Image](https://pbs.twimg.com/media/G_KozhraoAIOhNI?format=jpg&name=small)

